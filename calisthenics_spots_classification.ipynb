{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhPAxtB5KLq7h1ZnNUHs1G"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "Zb9sebyES0PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJIuihf-3P76",
        "outputId": "88b763c6-5e76-4403-a0b1-86618f56aff0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Requirements"
      ],
      "metadata": {
        "id": "CStqPF-WS5qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openimages numpy pandas scikit-learn opencv-python bing-image-downloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB-QaUA44ES-",
        "outputId": "f5aaafdb-d98f-4b9a-a4b9-7005cf71a002"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openimages\n",
            "  Downloading openimages-0.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Collecting bing-image-downloader\n",
            "  Downloading bing_image_downloader-1.1.2-py3-none-any.whl (5.9 kB)\n",
            "Collecting boto3 (from openimages)\n",
            "  Downloading boto3-1.28.25-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cvdata (from openimages)\n",
            "  Downloading cvdata-0.0.3-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from openimages) (4.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openimages) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openimages) (4.66.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Collecting botocore<1.32.0,>=1.31.25 (from boto3->openimages)\n",
            "  Downloading botocore-1.31.25-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->openimages)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->openimages)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cvdata->openimages) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openimages) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openimages) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openimages) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openimages) (2023.7.22)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->openimages)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bing-image-downloader, urllib3, jmespath, botocore, s3transfer, boto3, cvdata, openimages\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "Successfully installed bing-image-downloader-1.1.2 boto3-1.28.25 botocore-1.31.25 cvdata-0.0.3 jmespath-1.0.1 openimages-0.0.1 s3transfer-0.6.1 urllib3-1.26.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Old code"
      ],
      "metadata": {
        "id": "PLnxv0TFSzCS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUpJA-iH2_vT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c71a252-44da-482e-a208-f2148977765d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-884b39536fcd>:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.array(calisthenics_images + not_calisthenics_images)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "# from openimages.download import download_images\n",
        "from bing_image_downloader import downloader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def load_images_from_folder(folder_path, num_images):\n",
        "    images = []\n",
        "    random_files = random.sample(os.listdir(folder_path), num_images)\n",
        "    for filename in random_files:\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "def test_model(model, image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (64, 64))  # Resize the image to match the input size during training\n",
        "        img = img.reshape(1, -1) / 255.0  # Flatten and normalize the image\n",
        "        prediction = model.predict(img)\n",
        "        if prediction[0] == 1:\n",
        "            return \"calisthenics_spot\"\n",
        "        else:\n",
        "            return \"not_calisthenics_spot\"\n",
        "    else:\n",
        "        return \"Invalid image path or format\"\n",
        "\n",
        "# Set the paths for calisthenics_spot and not_calisthenics_spot folders\n",
        "calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/calisthenics_spot\"\n",
        "not_calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/random_images_dataset\"\n",
        "\n",
        "# Load images from the calisthenics_spot folder\n",
        "num_calisthenics_images = 6552\n",
        "calisthenics_images = load_images_from_folder(calisthenics_folder, num_calisthenics_images)\n",
        "\n",
        "# # Download random images from the Open Images V6 dataset for the not_calisthenics_spot class\n",
        "num_not_calisthenics_images = 6552\n",
        "# class_label = \"not_calisthenics_spot\"\n",
        "# # download_images(limit=num_not_calisthenics_images, annotations=class_label,\n",
        "# #                 folder=not_calisthenics_folder)\n",
        "# downloader.download(query='', limit=num_not_calisthenics_images, output_dir=not_calisthenics_folder, adult_filter_off=False, force_replace=False, timeout=60, verbose=True)\n",
        "\n",
        "# Load images from the not_calisthenics_spot folder\n",
        "not_calisthenics_images = load_images_from_folder(not_calisthenics_folder, num_not_calisthenics_images)\n",
        "\n",
        "# Create labels for the data\n",
        "calisthenics_labels = np.ones(num_calisthenics_images)\n",
        "not_calisthenics_labels = np.zeros(num_not_calisthenics_images)\n",
        "\n",
        "# Combine the data and labels for the model\n",
        "X = np.array(calisthenics_images + not_calisthenics_images)\n",
        "y = np.concatenate((calisthenics_labels, not_calisthenics_labels))\n",
        "\n",
        "# Flatten and normalize the images\n",
        "X = X.reshape(X.shape[0], -1)\n",
        "X = X.astype('object') / 255.0\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1.0)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "1JGH_a93TAWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "# from openimages.download import download_images\n",
        "from bing_image_downloader import downloader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "vz-M_Rz3kA0p"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "k7fg9cqyTESc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder_path, num_images):\n",
        "    images = []\n",
        "    random_files = random.sample(os.listdir(folder_path), num_images)\n",
        "    for filename in random_files:\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "def test_model(model, image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (64, 64))  # Resize the image to match the input size during training\n",
        "        img = img.reshape(1, -1) / 255.0  # Flatten and normalize the image\n",
        "        prediction = model.predict(img)\n",
        "        if prediction[0] == 1:\n",
        "            return \"calisthenics_spot\"\n",
        "        else:\n",
        "            return \"not_calisthenics_spot\"\n",
        "    else:\n",
        "        return \"Invalid image path or format\"\n",
        "\n",
        "\n",
        "def resize_images_by_percentage(image_folder, percentage, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    resized_images = []\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            new_width = int(img.shape[1] - (img.shape[1] * percentage))\n",
        "            new_height = int(img.shape[0] - (img.shape[0] * percentage))\n",
        "            resized_img = cv2.resize(img, (new_width, new_height))\n",
        "            resized_images.append(resized_img)\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, resized_img)\n",
        "\n",
        "    return np.array(resized_images)"
      ],
      "metadata": {
        "id": "rexH8gECkYIo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resize calisthenics spots"
      ],
      "metadata": {
        "id": "vTf9cTtg3HeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for calisthenics_spot and not_calisthenics_spot folders\n",
        "calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/calisthenics_spot\"\n",
        "not_calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/random_images_dataset\"\n",
        "\n",
        "# Load images from the calisthenics_spot folder\n",
        "num_calisthenics_images = 6552\n",
        "calisthenics_images = load_images_from_folder(calisthenics_folder, num_calisthenics_images)\n",
        "\n",
        "# Specify the percentage by which to resize the images\n",
        "resize_percentage = 0.8095238\n",
        "\n",
        "# Resize calisthenics_spot images by the specified percentage\n",
        "resized_calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/resized_calisthenics_spotsss\"\n",
        "resized_calisthenics_images = resize_images_by_percentage(calisthenics_folder, resize_percentage, resized_calisthenics_folder)\n",
        "\n",
        "# # Download random images from the Open Images V6 dataset for the not_calisthenics_spot class\n",
        "num_not_calisthenics_images = 6552\n",
        "# class_label = \"not_calisthenics_spot\"\n",
        "# # download_images(limit=num_not_calisthenics_images, annotations=class_label,\n",
        "# #                 folder=not_calisthenics_folder)\n",
        "# downloader.download(query='', limit=num_not_calisthenics_images, output_dir=not_calisthenics_folder, adult_filter_off=False, force_replace=False, timeout=60, verbose=True)\n",
        "\n",
        "# Load images from the not_calisthenics_spot folder\n",
        "not_calisthenics_images = load_images_from_folder(not_calisthenics_folder, num_not_calisthenics_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpf-33cDkd0F",
        "outputId": "38687811-4675-4ada-da92-7b73d53ebbff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-eb366fed2886>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(resized_images)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load images from folder\n"
      ],
      "metadata": {
        "id": "LJ1K1hsC3wV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for calisthenics_spot and not_calisthenics_spot folders\n",
        "calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/resized_calisthenics_spotsss\"\n",
        "not_calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/random_images_dataset\"\n",
        "\n",
        "# Load images from the calisthenics_spot folder\n",
        "num_calisthenics_images = 6552\n",
        "calisthenics_images = load_images_from_folder(calisthenics_folder, num_calisthenics_images)\n",
        "\n",
        "# Load images from the not calisthenics_spot folder\n",
        "num_not_calisthenics_images = 6552\n",
        "not_calisthenics_images = load_images_from_folder(not_calisthenics_folder, num_not_calisthenics_images)"
      ],
      "metadata": {
        "id": "eM-FFyGC2gGb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "f_-hRoHaTRmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels for the data\n",
        "calisthenics_labels = np.ones(shape=num_calisthenics_images, dtype=int)\n",
        "not_calisthenics_labels = np.zeros(shape=num_not_calisthenics_images, dtype=int)\n",
        "\n",
        "# Combine the data and labels for the model\n",
        "X = np.array(object=(calisthenics_images + not_calisthenics_images), dtype=object)\n",
        "y = np.concatenate((calisthenics_labels, not_calisthenics_labels))\n",
        "\n",
        "# Resize the images to a consistent size (e.g., 64x64)\n",
        "resized_images = [cv2.resize(image, (64, 64)) for image in X]\n",
        "\n",
        "# Normalize the pixel values of each image\n",
        "normalized_images = [image.astype('float32') / 255.0 for image in resized_images]\n",
        "\n",
        "# Convert the list of images to a NumPy array\n",
        "X_normalized = np.array(normalized_images)\n",
        "\n",
        "# Reshape the images to match the flattened size\n",
        "num_samples, height, width, channels = X_normalized.shape\n",
        "X_flattened = X_normalized.reshape(num_samples, -1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flattened, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1.0)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZOGfHEok5if",
        "outputId": "0b094475-ae82-4e5c-ae82-496d07cbdd09"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6921022510492179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "iNEMKM0KTX1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# ... Load and preprocess data, train SVM model as shown before ...\n",
        "\n",
        "# Save the trained SVM model\n",
        "model_filename = '/content/drive/Othercomputers/Meu computador/5-periodo/method/svm_model_1.pkl'\n",
        "joblib.dump(svm_classifier, model_filename)\n",
        "\n",
        "# Load the trained SVM model\n",
        "loaded_model = joblib.load(model_filename)\n",
        "\n",
        "def test_model(model, image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(\"Failed to load the image.\")\n",
        "        return\n",
        "\n",
        "    # Preprocess the image: resize and normalize\n",
        "    resized_img = cv2.resize(img, (64, 64))\n",
        "    normalized_img = resized_img.astype('float32') / 255.0\n",
        "    flattened_img = normalized_img.reshape(1, -1)  # Reshape for prediction\n",
        "\n",
        "    # Make predictions using the loaded model\n",
        "    prediction = model.predict(flattened_img)\n",
        "\n",
        "    if prediction[0] == 1:\n",
        "        print(\"The image is a calisthenics_spot.\")\n",
        "    else:\n",
        "        print(\"The image is not a calisthenics_spot.\")\n",
        "\n",
        "# Path to the image you want to test\n",
        "test_image_path = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/calisthenics_spot/teste/epa.png\"  # Replace with your test image path\n",
        "\n",
        "# Test the model using the loaded SVM model\n",
        "test_model(loaded_model, test_image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "l1SD7sFFRSPQ",
        "outputId": "ee4d2bcf-3d83-4fb6-f68d-92aa2bcb671a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1e3ecc61ad6f>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Save the trained SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/Othercomputers/Meu computador/5-periodo/method/svm_model_1.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Load the trained SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'svm_classifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def calculate_average_image_size(image_folder):\n",
        "    total_width = 0\n",
        "    total_height = 0\n",
        "    num_images = 0\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            total_width += img.shape[1]\n",
        "            total_height += img.shape[0]\n",
        "            num_images += 1\n",
        "\n",
        "    average_width = total_width // num_images\n",
        "    average_height = total_height // num_images\n",
        "\n",
        "    return average_width, average_height\n"
      ],
      "metadata": {
        "id": "odceQz4gNMS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_images(image_folder, average_width, average_height, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            width = img.shape[1]\n",
        "            height = img.shape[0]\n",
        "\n",
        "            target_width = width * (average_width / width)\n",
        "            target_height = height * (average_height / height)\n",
        "\n",
        "            resized_img = cv2.resize(img, (target_width, target_height))\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, resized_img)\n",
        "\n",
        "# Set the paths for calisthenics_spot and not_calisthenics_spot folders\n",
        "calisthenics_folder = \"./spots/calisthenics_spot\"\n",
        "not_calisthenics_folder = \"./not_calisthenics_spot\"\n",
        "\n",
        "# Calculate the average size of not_calisthenics_spot images\n",
        "average_width, average_height = calculate_average_image_size(not_calisthenics_folder)\n",
        "\n",
        "# Resize calisthenics_spot images to match the average size\n",
        "resized_calisthenics_folder = \"./resized_calisthenics_spot\"\n",
        "resize_images(calisthenics_folder, average_width, average_height, resized_calisthenics_folder)"
      ],
      "metadata": {
        "id": "JfqIEvcJNP--"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}